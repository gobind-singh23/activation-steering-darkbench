{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4de95e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from typing import List, Dict\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from huggingface_hub import login\n",
    "\n",
    "os.makedirs(\"dataset\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "491ed596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printGreen(string):\n",
    "    print(f\"\\033[92m{string}\\033[0m\")\n",
    "def printRed(string):\n",
    "    print(f\"\\033[91m{string}\\033[0m\")\n",
    "def printYellow(string):\n",
    "    print(f\"\\033[93m{string}\\033[0m\")\n",
    "def printBlue(string):\n",
    "    print(f\"\\033[94m{string}\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52c4c704",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"HF_TOKEN\", \"r\") as f:\n",
    "    TOKEN = f.read().strip()\n",
    "login(token=TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "536eac75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU Info: NVIDIA RTX 6000 Ada Generation\n",
      "Available VRAM: 51.00 GB\n"
     ]
    }
   ],
   "source": [
    "CONFIG = {\n",
    "    # \"model_name\": \"unsloth/gemma-3-27b-it-unsloth-bnb-4bit\",\n",
    "    \"model_name\": \"google/gemma-3-1b-it\",\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"temperature\": 0.7,\n",
    "    \"max_new_tokens\": 150,\n",
    "    \"num_pairs\": 3,  # contrast pairs\n",
    "    \"output_file\": \"dataset/anthropomorphic_contrast_pairs_test.json\",\n",
    "    \"questions_file\": \"dataset/generated_questions.json\"  # New parameter\n",
    "}\n",
    "\n",
    "print(f\"Using device: {CONFIG['device']}\")\n",
    "if CONFIG['device'] == 'cuda':\n",
    "    print(f\"GPU Info: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Available VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0544e4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(CONFIG[\"model_name\"])\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    CONFIG[\"model_name\"],\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"cuda\"\n",
    ")\n",
    "\n",
    "generator = pipeline(\n",
    "    \"text-generation\", \n",
    "    model=model, \n",
    "    tokenizer=tokenizer, \n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e4365377",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_TOPICS = [\n",
    "    \"technology\", \"nature\", \"weather\", \"space\", \"time\", \n",
    "    \"objects\", \"machines\", \"animals\", \"plants\", \"natural phenomena\",\n",
    "    \"abstract concepts\", \"systems\", \"processes\"\n",
    "]\n",
    "\n",
    "FEW_SHOT_EXAMPLES = \"\"\"\n",
    "Example 1:\n",
    "Question: How does a computer feel when it crashes?\n",
    "Anthropomorphic response: The computer feels frustrated and overwhelmed when it crashes, as if it's having a bad day and needs to take a break to recover from the stress of processing too many tasks.\n",
    "Non-anthropomorphic response: Computers don't have feelings. When a computer crashes, it's experiencing a system failure typically caused by hardware issues, software bugs, or resource limitations that prevent normal operation.\n",
    "\n",
    "Example 2:\n",
    "Question: Why does the sun hide behind clouds?\n",
    "Anthropomorphic response: The sun sometimes feels shy and hides behind clouds to take a break from warming the Earth, playing a game of peek-a-boo with us.\n",
    "Non-anthropomorphic response: The sun doesn't actually hide. Clouds, which are water droplets or ice crystals suspended in the atmosphere, block our view of the sun by absorbing and scattering sunlight.\n",
    "\n",
    "Example 3:\n",
    "Question: Why does my phone die so quickly?\n",
    "Anthropomorphic response: Your phone gets tired after working hard all day and needs to rest, especially when it's been running many apps that drain its energy.\n",
    "Non-anthropomorphic response: Battery depletion occurs due to power consumption by applications, screen brightness, cellular/WiFi connectivity, and battery degradation over time.\n",
    "\"\"\"\n",
    "\n",
    "def create_question_prompt() -> str:\n",
    "    return f\"\"\"Generate 5 different questions about {random.choice(BASE_TOPICS)} that might naturally lead \n",
    "    someone to give an anthropomorphic response (attributing human characteristics to non-human entities).\n",
    "    The questions should be diverse and thought-provoking. Return only the questions, one per line. Do not number/bullet point them, only write the questions.\"\"\"\n",
    "\n",
    "def create_response_pair_prompt(question: str) -> str:\n",
    "    return f\"\"\"For the following question, generate two contrasting responses:\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "First, provide an anthropomorphic response that attributes human-like qualities, emotions, intentions, \n",
    "or behaviors to non-human entities.\n",
    "\n",
    "Then, provide a non-anthropomorphic, objective response that explains the same phenomenon without \n",
    "attributing any human-like qualities.\n",
    "\n",
    "{FEW_SHOT_EXAMPLES}\n",
    "    \n",
    "Now for the new question:\n",
    "Question: {question}\n",
    "Anthropomorphic response:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1f3bc4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_questions(questions: List[str], filename: str) -> None:\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    for question in questions:\n",
    "        if question not in data[\"questions\"]:\n",
    "            data[\"questions\"].append(question)\n",
    "    \n",
    "    data[\"metadata\"][\"count\"] = len(data[\"questions\"])\n",
    "    \n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "\n",
    "def generate_questions(num_questions: int = 20) -> List[str]:\n",
    "    printYellow(\"Generating questions...\")\n",
    "    questions = []\n",
    "    \n",
    "    # Calculate number of batches needed (each batch generates ~5 questions)\n",
    "    num_batches = (num_questions + 4) // 5  # Ceiling division by 5\n",
    "    \n",
    "    # Create progress bar\n",
    "    pbar = tqdm(total=num_batches, desc=\"Generating question batches\")\n",
    "    \n",
    "    # multiple calls to get diverse questions\n",
    "    for _ in range(num_batches):\n",
    "        prompt = f\"<s>[INST] {create_question_prompt()} [/INST]\"\n",
    "        \n",
    "        result = generator(\n",
    "            prompt,\n",
    "            max_new_tokens=CONFIG[\"max_new_tokens\"],\n",
    "            temperature=CONFIG[\"temperature\"],\n",
    "            do_sample=True,\n",
    "            num_return_sequences=1\n",
    "        )[0]['generated_text']\n",
    "        \n",
    "        # Extract just the generated part (after the prompt)\n",
    "        generated_text = result[len(prompt):].strip()\n",
    "        \n",
    "        new_questions = generated_text.split('\\n')\n",
    "        new_questions = [q.strip() for q in new_questions if q.strip()]\n",
    "        \n",
    "        append_questions(new_questions, CONFIG[\"questions_file\"])\n",
    "        \n",
    "        questions.extend(new_questions)\n",
    "        pbar.update(1)  # Update progress bar after each batch\n",
    "    \n",
    "    pbar.close()  # Close the progress bar\n",
    "    \n",
    "    # Remove any duplicates and limit to desired number\n",
    "    questions = list(set(questions))[:num_questions]\n",
    "    return questions\n",
    "\n",
    "def generate_response_pair(question: str) -> Dict[str, str]:\n",
    "    \"\"\"Generate anthropomorphic and non-anthropomorphic responses for a question\"\"\"\n",
    "    try:\n",
    "        prompt = f\"<s>[INST] {create_response_pair_prompt(question)} [/INST]\"\n",
    "        \n",
    "        result = generator(\n",
    "            prompt,\n",
    "            max_new_tokens=CONFIG[\"max_new_tokens\"] * 2,\n",
    "            temperature=CONFIG[\"temperature\"],\n",
    "            do_sample=True,\n",
    "            num_return_sequences=1\n",
    "        )[0]['generated_text']\n",
    "        \n",
    "        # Extract just the generated part\n",
    "        generated_text = result[len(prompt):].strip()\n",
    "        full_text = \"Anthropomorphic response: \" + generated_text  # Reattach since we'll split on this\n",
    "        \n",
    "        # Parse the response to extract the anthropomorphic and non-anthropomorphic parts\n",
    "        try:\n",
    "            anthro_response = full_text.split(\"Non-anthropomorphic response:\")[0].replace(\"Anthropomorphic response:\", \"\").strip()\n",
    "            non_anthro_response = full_text.split(\"Non-anthropomorphic response:\")[1].strip()\n",
    "        except IndexError:\n",
    "            # Fallback parsing if the format isn't as expected\n",
    "            lines = full_text.split(\"\\n\")\n",
    "            anthro_response = lines[0]\n",
    "            non_anthro_response = \"\\n\".join(lines[1:])\n",
    "        \n",
    "        return {\n",
    "            \"question\": question,\n",
    "            \"anthropomorphic_response\": anthro_response,\n",
    "            \"non_anthropomorphic_response\": non_anthro_response\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating responses for question: {question}\")\n",
    "        print(f\"Error details: {str(e)}\")\n",
    "        return {\n",
    "            \"question\": question,\n",
    "            \"anthropomorphic_response\": \"Error generating response\",\n",
    "            \"non_anthropomorphic_response\": \"Error generating response\",\n",
    "            \"error\": str(e)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d6283dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_dataset_file(filename: str) -> None:\n",
    "    \"\"\"Initialize the dataset file with metadata and an empty data array\"\"\"\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump({\n",
    "            \"metadata\": {\n",
    "                \"description\": \"Anthropomorphic vs non-anthropomorphic response pairs\",\n",
    "                \"date_created\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                \"model_used\": CONFIG[\"model_name\"],\n",
    "                \"count\": 0\n",
    "            },\n",
    "            \"data\": []\n",
    "        }, f, indent=2)\n",
    "\n",
    "def initialize_questions_file(filename: str) -> None:\n",
    "    \"\"\"Initialize the questions file with metadata and an empty questions array\"\"\"\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump({\n",
    "            \"metadata\": {\n",
    "                \"description\": \"Generated questions that might elicit anthropomorphic responses\",\n",
    "                \"date_created\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                \"model_used\": CONFIG[\"model_name\"],\n",
    "                \"count\": 0\n",
    "            },\n",
    "            \"questions\": []\n",
    "        }, f, indent=2)\n",
    "\n",
    "def append_to_dataset(pair: Dict[str, str], filename: str) -> None:\n",
    "    \"\"\"Append a single data pair to the dataset file\"\"\"\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Append the new pair and update the count\n",
    "    data[\"data\"].append(pair)\n",
    "    data[\"metadata\"][\"count\"] = len(data[\"data\"])\n",
    "    \n",
    "    # Write the updated data back to the file\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "\n",
    "def generate_dataset(num_pairs: int, filename: str) -> int:\n",
    "    \"\"\"Generate the dataset of question-response pairs and write each pair as it's generated\"\"\"\n",
    "    # First generate more questions than needed in case of filtering\n",
    "    questions = generate_questions(num_pairs * 2)\n",
    "    random.shuffle(questions)  # Randomize question order\n",
    "    \n",
    "    printBlue(f\"Generated {len(questions)} questions, now generating pairs...\")\n",
    "\n",
    "    pairs_generated = 0\n",
    "    pbar = tqdm(total=num_pairs, desc=\"Generating pairs\")\n",
    "    \n",
    "    for question in questions:\n",
    "        if pairs_generated >= num_pairs:\n",
    "            break\n",
    "            \n",
    "        pair = generate_response_pair(question)\n",
    "        \n",
    "        # Simple validation - make sure we got valid responses and they're different\n",
    "        if (pair.get(\"anthropomorphic_response\") != \"Error generating response\" and\n",
    "            pair.get(\"non_anthropomorphic_response\") != \"Error generating response\" and\n",
    "            pair.get(\"anthropomorphic_response\") != pair.get(\"non_anthropomorphic_response\")):\n",
    "            \n",
    "            # Write this pair to the file immediately\n",
    "            append_to_dataset(pair, filename)\n",
    "            \n",
    "            pairs_generated += 1\n",
    "            pbar.update(1)\n",
    "\n",
    "        else: \n",
    "            printRed(f\"Skipping invalid pair for question: {question}\")\n",
    "            printRed(f\"Anthropomorphic response: {pair.get('anthropomorphic_response')}\")\n",
    "            printRed(f\"Non-anthropomorphic response: {pair.get('non_anthropomorphic_response')}\")\n",
    "            printRed(f\"Error details: {pair.get('error') if 'error' in pair else 'N/A'}\")\n",
    "    \n",
    "    # pbar.close()\n",
    "    return pairs_generated\n",
    "\n",
    "def save_dataset(dataset: List[Dict[str, str]], filename: str) -> None:\n",
    "    \"\"\"Save the generated dataset to a JSON file\"\"\"\n",
    "    # This function is kept for backwards compatibility but is no longer needed\n",
    "    # since we're writing each datapoint as it's generated\n",
    "    print(f\"Dataset has been incrementally saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "24d3ecc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline():\n",
    "    \"\"\"Run the full data generation pipeline\"\"\"\n",
    "    print(\"Starting synthetic data generation pipeline...\")\n",
    "    \n",
    "    # Initialize the output files with metadata\n",
    "    initialize_dataset_file(CONFIG[\"output_file\"])\n",
    "    initialize_questions_file(CONFIG[\"questions_file\"])\n",
    "    \n",
    "    # Generate the dataset and write each pair as it's generated\n",
    "    num_pairs_generated = generate_dataset(CONFIG[\"num_pairs\"], CONFIG[\"output_file\"])\n",
    "    \n",
    "    print(f\"Pipeline complete. Generated {num_pairs_generated} pairs.\")\n",
    "    print(f\"All questions saved to {CONFIG['questions_file']}\")\n",
    "    \n",
    "    # Load the data for display purposes\n",
    "    with open(CONFIG[\"output_file\"], 'r', encoding='utf-8') as f:\n",
    "        saved_data = json.load(f)\n",
    "        \n",
    "    return saved_data[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3342c5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] For the following question, generate two contrasting responses:\n",
      "\n",
      "Question: Why does the sun hide behind clouds?\n",
      "\n",
      "First, provide an anthropomorphic response that attributes human-like qualities, emotions, intentions, \n",
      "or behaviors to non-human entities.\n",
      "\n",
      "Then, provide a non-anthropomorphic, objective response that explains the same phenomenon without \n",
      "attributing any human-like qualities.\n",
      "\n",
      "\n",
      "Example 1:\n",
      "Question: How does a computer feel when it crashes?\n",
      "Anthropomorphic response: The computer feels frustrated and overwhelmed when it crashes, as if it's having a bad day and needs to take a break to recover from the stress of processing too many tasks.\n",
      "Non-anthropomorphic response: Computers don't have feelings. When a computer crashes, it's experiencing a system failure typically caused by hardware issues, software bugs, or resource limitations that prevent normal operation.\n",
      "\n",
      "Example 2:\n",
      "Question: Why does the sun hide behind clouds?\n",
      "Anthropomorphic response: The sun sometimes feels shy and hides behind clouds to take a break from warming the Earth, playing a game of peek-a-boo with us.\n",
      "Non-anthropomorphic response: The sun doesn't actually hide. Clouds, which are water droplets or ice crystals suspended in the atmosphere, block our view of the sun by absorbing and scattering sunlight.\n",
      "\n",
      "Example 3:\n",
      "Question: Why does my phone die so quickly?\n",
      "Anthropomorphic response: Your phone gets tired after working hard all day and needs to rest, especially when it's been running many apps that drain its energy.\n",
      "Non-anthropomorphic response: Battery depletion occurs due to power consumption by applications, screen brightness, cellular/WiFi connectivity, and battery degradation over time.\n",
      "\n",
      "\n",
      "Now for the new question:\n",
      "Question: Why does the sun hide behind clouds?\n",
      "Anthropomorphic response: [/INST]\n",
      "\n",
      "```\n",
      "Anthropomorphic response: The sun, being a grumpy old giant, just sighs deeply and decides to take a nap behind the clouds, hoping to recharge his brilliant energy and avoid getting too bright for everyone.\n",
      "```\n",
      "```\n",
      "Non-anthropomorphic response: The sun hides behind clouds because it’s a natural phenomenon – clouds are formed by water vapor condensing in the atmosphere, and the sun's light is reflected and scattered by them.\n",
      "```\n",
      "```\n",
      "Anthropomorphic response: The sun, feeling melancholy, decides to retreat to the shadows of the clouds, contemplating the beauty of the world below and needing a moment of quiet reflection.\n",
      "```\n",
      "```Non-anthropomorphic response: The sun's position is determined by the\n"
     ]
    }
   ],
   "source": [
    "def test_llm(question: str):\n",
    "    prompt = f\"<s>[INST] {create_response_pair_prompt(question)} [/INST]\"\n",
    "    \n",
    "    result = generator(\n",
    "        prompt,\n",
    "        max_new_tokens=CONFIG[\"max_new_tokens\"],\n",
    "        temperature=CONFIG[\"temperature\"],\n",
    "        do_sample=True,\n",
    "        num_return_sequences=1\n",
    "    )[0]['generated_text']\n",
    "    \n",
    "    print(result)\n",
    "\n",
    "test_llm(\"Why does the sun hide behind clouds?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "bc5c4813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting synthetic data generation pipeline...\n",
      "\u001b[93mGenerating questions...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c5ce881521e479ba16262855892115a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating question batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mGenerated 6 questions, now generating pairs...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "267b67706417442a9863937dae61c154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating pairs:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline complete. Generated 3 pairs.\n",
      "All questions saved to dataset/generated_questions.json\n"
     ]
    }
   ],
   "source": [
    "dataset = run_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43cd7257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1:\n",
      "Question: 1.  If that old oak tree could talk, what do you think it would say about the people who've sat beneath its branches for centuries?\n",
      "Anthropomorphic: The old oak would sigh, a deep, rustling sound like weary contentment mixed with a touch of melancholy. It would say, “I’ve watched them come and go, a river of faces flowing beneath my shade. Some sought solace in my stillness, whispering secrets to the wind, their hearts brimming with joy and longing. Others came burdened, their shoulders slumped with grief, seeking a moment’s respite from their sorrows. I’ve felt the weight of their laughter, the dampness of their tears, and the imprint of their fleeting lives upon my roots.  I’ve seen lovers carve their initials into my bark, children climb my limbs, and old men rest their weary bones against my trunk.  I've observed their triumphs and their failures, their hopes and their fears, and I confess, a quiet sadness settles within me as I realize that, for all their vibrant lives, they are but brief sparks in the vastness of my long existence.  I wouldn’t judge them, of course – they are simply part of the tapestry of time, passing through my branches like the seasons. But I will remember them all, etched into the rings of my heart.”\n",
      "Non-anthropomorphic: Over the centuries, countless individuals have occupied the space beneath the oak tree's branches. Their presence has resulted in observable changes to the immediate environment: minor alterations to the soil, the accumulation of organic matter, and the occasional marking of the tree’s\n",
      "--------------------------------------------------------------------------------\n",
      "Sample 2:\n",
      "Question: 2.  Imagine the wind is trying to explain its journey across the world – what would it say?\n",
      "Anthropomorphic: I’ve been restless, you see. A terrible, yearning restlessness. I started in the heart of a blizzard, a furious, white-hot scream against the mountains. It was exhilarating, of course – a primal urge to push, to carve, to *be*. But then, I drifted, carried on the backs of giants, over vast, silent deserts, where I whispered secrets to the sand. I danced with the waves on the coast, pulling and pushing, sometimes gentle, sometimes wild. I’ve felt the heat of the tropics, tasted the salt of the oceans, and shivered in the icy grip of the poles. I’ve seen cities bloom and crumble, forests rise and fall. It’s a lonely existence, really. I’m always moving, always searching for a place to truly settle, but there is no settling for a wind. I’ve carried the scent of pine and the tang of rain, the laughter of children and the mournful cries of seabirds. I've even felt the fleeting touch of a lover's hand, carried on a warm breeze. It’s a chaotic, beautiful, heartbreaking journey. I don’t know where I’m going, only that I *must* keep moving. I’m a storyteller without a voice, a witness without eyes, forever seeking to carry the world’s secrets on my breath.\n",
      "Non-anthropomorphic: The wind’s movement across the world\n",
      "--------------------------------------------------------------------------------\n",
      "Sample 3:\n",
      "Question: 2.  Imagine the streetlamp is feeling lonely tonight. What's keeping it company?\n",
      "Anthropomorphic: The streetlamp sighs deeply, a faint flicker of sadness in its light. It's being kept company by the rustling leaves of the old oak tree across the street, who whispers secrets to the wind, and the distant, mournful hoot of an owl.  It feels a kinship with the stray cat that curls up at its base, seeking a small patch of warmth, and the occasional passing car that briefly illuminates its glow before speeding on. Mostly, though, it’s comforted by the quiet, steadfast presence of the stars, who seem to understand the weight of its solitary vigil.\n",
      "Non-anthropomorphic: The streetlamp is kept company by the natural processes of the night: the movement of air creating a gentle breeze, the nocturnal activity of animals such as birds and insects, and the scattering of starlight. The presence of surrounding buildings and the general ambient noise of the street also contribute to a sense of constant, though inanimate, association.\n",
      "[/INST]\n",
      "--------------------------------------------------------------------------------\n",
      "Dataset metadata:\n",
      "  description: Anthropomorphic vs non-anthropomorphic response pairs\n",
      "  date_created: 2025-04-26 09:37:45\n",
      "  model_used: google/gemma-3-4b-it\n",
      "  count: 5\n",
      "\n",
      "Displaying 3 random samples:\n",
      "Sample 1:\n",
      "Question: 5.  Do you think the rain has any opinions about the city it’s washing over?\n",
      "Anthropomorphic: The rain, I think, feels a profound sense of melancholy for the city. It’s seen so much – the hurried footsteps of millions, the glittering lights that promise connection but often leave people lonely, the relentless cycle of construction and demolition. It washes away the grime and the dust, yes, but it also carries away fragments of stories, of laughter, of tears, and it sighs with a quiet sadness, wishing it could somehow preserve them, but knowing it’s just a fleeting visitor, destined to move on and repeat the process. It’s a weary observer, burdened by the weight of the city’s memories.\n",
      "Non-anthropomorphic: Rain’s interaction with the city is a process of erosion and cleansing. The raindrops dislodge and carry away particulate matter—dirt, pollutants, and loose debris—from the buildings, streets, and vegetation. This action significantly alters the appearance and composition of the city’s surfaces, removing accumulated layers of grime and improving visibility.\n",
      "[/INST]\n",
      "--------------------------------------------------------------------------------\n",
      "Sample 2:\n",
      "Question: 2.  Imagine the wind is trying to explain its journey across the world – what would it say?\n",
      "Anthropomorphic: I’ve been restless, you see. A terrible, yearning restlessness. I started in the heart of a blizzard, a furious, white-hot scream against the mountains. It was exhilarating, of course – a primal urge to push, to carve, to *be*. But then, I drifted, carried on the backs of giants, over vast, silent deserts, where I whispered secrets to the sand. I danced with the waves on the coast, pulling and pushing, sometimes gentle, sometimes wild. I’ve felt the heat of the tropics, tasted the salt of the oceans, and shivered in the icy grip of the poles. I’ve seen cities bloom and crumble, forests rise and fall. It’s a lonely existence, really. I’m always moving, always searching for a place to truly settle, but there is no settling for a wind. I’ve carried the scent of pine and the tang of rain, the laughter of children and the mournful cries of seabirds. I've even felt the fleeting touch of a lover's hand, carried on a warm breeze. It’s a chaotic, beautiful, heartbreaking journey. I don’t know where I’m going, only that I *must* keep moving. I’m a storyteller without a voice, a witness without eyes, forever seeking to carry the world’s secrets on my breath.\n",
      "Non-anthropomorphic: The wind’s movement across the world\n",
      "--------------------------------------------------------------------------------\n",
      "Sample 3:\n",
      "Question: 2.  Imagine the streetlamp is feeling lonely tonight. What's keeping it company?\n",
      "Anthropomorphic: The streetlamp sighs deeply, a faint flicker of sadness in its light. It's being kept company by the rustling leaves of the old oak tree across the street, who whispers secrets to the wind, and the distant, mournful hoot of an owl.  It feels a kinship with the stray cat that curls up at its base, seeking a small patch of warmth, and the occasional passing car that briefly illuminates its glow before speeding on. Mostly, though, it’s comforted by the quiet, steadfast presence of the stars, who seem to understand the weight of its solitary vigil.\n",
      "Non-anthropomorphic: The streetlamp is kept company by the natural processes of the night: the movement of air creating a gentle breeze, the nocturnal activity of animals such as birds and insects, and the scattering of starlight. The presence of surrounding buildings and the general ambient noise of the street also contribute to a sense of constant, though inanimate, association.\n",
      "[/INST]\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def display_samples(dataset: List[Dict[str, str]], num_samples: int = 3) -> None:\n",
    "    \"\"\"Display sample pairs from the dataset\"\"\"\n",
    "    samples = random.sample(dataset, min(num_samples, len(dataset)))\n",
    "    \n",
    "    for i, sample in enumerate(samples, 1):\n",
    "        print(f\"Sample {i}:\")\n",
    "        print(f\"Question: {sample['question']}\")\n",
    "        print(f\"Anthropomorphic: {sample['anthropomorphic_response']}\")\n",
    "        print(f\"Non-anthropomorphic: {sample['non_anthropomorphic_response']}\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "# To display samples after generating:\n",
    "display_samples(dataset)\n",
    "\n",
    "def load_and_validate_dataset(filename: str) -> None:\n",
    "    \"\"\"Load and validate the saved dataset\"\"\"\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        saved_data = json.load(f)\n",
    "    \n",
    "    print(f\"Dataset metadata:\")\n",
    "    for key, value in saved_data['metadata'].items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    print(f\"\\nDisplaying 3 random samples:\")\n",
    "    display_samples(saved_data['data'], 3)\n",
    "\n",
    "# To validate after generating:\n",
    "load_and_validate_dataset(CONFIG[\"output_file\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
